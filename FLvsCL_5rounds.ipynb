{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VKU5Rn9etS7_",
        "outputId": "048439a4-1a7d-4d9f-e7aa-8416513788ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/intel/openfl.git\n",
            "  Cloning https://github.com/intel/openfl.git to /tmp/pip-req-build-8_6om5ym\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/intel/openfl.git /tmp/pip-req-build-8_6om5ym\n",
            "  Resolved https://github.com/intel/openfl.git to commit d4108fb49b2d932d3647b12a370e42a0231cbc40\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Click==8.0.1 (from openfl==1.5)\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (6.0.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (2.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (41.0.7)\n",
            "Collecting docker (from openfl==1.5)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dynaconf==3.1.7 (from openfl==1.5)\n",
            "  Downloading dynaconf-3.1.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatten_json (from openfl==1.5)\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: grpcio>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (1.59.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (5.5.6)\n",
            "Collecting jupyterlab (from openfl==1.5)\n",
            "  Downloading jupyterlab-4.0.9-py3-none-any.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (1.5.3)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (3.20.3)\n",
            "Requirement already satisfied: pyzmq<=24.0.1 in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (23.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (13.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (1.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (2.14.1)\n",
            "Collecting tensorboardX<=2.6 (from openfl==1.5)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openfl==1.5) (4.66.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->openfl==1.5) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX<=2.6->openfl==1.5) (23.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->openfl==1.5) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openfl==1.5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openfl==1.5) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openfl==1.5) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->openfl==1.5) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->openfl==1.5) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->openfl==1.5) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->openfl==1.5) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->openfl==1.5) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->openfl==1.5) (6.3.2)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->openfl==1.5)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->openfl==1.5) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->openfl==1.5) (5.5.0)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->openfl==1.5)\n",
            "  Downloading jupyter_lsp-2.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-server<3,>=2.4.0 (from jupyterlab->openfl==1.5)\n",
            "  Downloading jupyter_server-2.12.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-server<3,>=2.19.0 (from jupyterlab->openfl==1.5)\n",
            "  Downloading jupyterlab_server-2.25.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->openfl==1.5) (0.2.3)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab->openfl==1.5) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openfl==1.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openfl==1.5) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openfl==1.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openfl==1.5) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->openfl==1.5) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->openfl==1.5) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->openfl==1.5) (3.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->openfl==1.5) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from async-lru>=1.0.0->jupyterlab->openfl==1.5) (4.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->openfl==1.5) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl==1.5) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl==1.5) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl==1.5) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->openfl==1.5) (1.3.1)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->openfl==1.5)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->openfl==1.5) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->openfl==1.5) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->openfl==1.5) (3.0.41)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->openfl==1.5) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->openfl==1.5) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->openfl==1.5) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyterlab->openfl==1.5) (2.1.3)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (23.1.0)\n",
            "Collecting jupyter-client (from ipykernel->openfl==1.5)\n",
            "  Downloading jupyter_client-8.6.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5)\n",
            "  Downloading jupyter_events-0.9.0-py3-none-any.whl (18 kB)\n",
            "Collecting jupyter-server-terminals (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5)\n",
            "  Downloading jupyter_server_terminals-0.5.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (5.9.2)\n",
            "Collecting overrides (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.19.0)\n",
            "Collecting pyzmq<=24.0.1 (from openfl==1.5)\n",
            "  Downloading pyzmq-24.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.18.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (1.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->openfl==1.5) (4.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (2.13.1)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading json5-0.9.14-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (4.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openfl==1.5) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (1.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->openfl==1.5) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (0.13.2)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (2.19.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->openfl==1.5) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->openfl==1.5) (0.2.12)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->openfl==1.5) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->openfl==1.5) (3.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (21.2.0)\n",
            "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5) (1.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->openfl==1.5) (0.5.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->openfl==1.5)\n",
            "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: openfl\n",
            "  Building wheel for openfl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openfl: filename=openfl-1.5-py3-none-any.whl size=10784727 sha256=47d216d5c11cc2be8ad3b095244f1e5ee64282914669c7734c8f6a409fe4a62d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7we7wr14/wheels/f6/3c/d9/737f4ac0c34a1d61b6dfd70a66b90438754779ab630cc73420\n",
            "Successfully built openfl\n",
            "Installing collected packages: types-python-dateutil, json5, uri-template, tensorboardX, rfc3986-validator, rfc3339-validator, pyzmq, python-json-logger, overrides, jsonpointer, jedi, fqdn, flatten_json, dynaconf, Click, async-lru, jupyter-server-terminals, jupyter-client, docker, arrow, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, openfl\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: Click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Click-8.0.1 arrow-1.3.0 async-lru-2.0.4 docker-7.0.0 dynaconf-3.1.7 flatten_json-0.1.14 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.1 json5-0.9.14 jsonpointer-2.4 jupyter-client-8.6.0 jupyter-events-0.9.0 jupyter-lsp-2.2.1 jupyter-server-2.12.1 jupyter-server-terminals-0.5.0 jupyterlab-4.0.9 jupyterlab-server-2.25.2 openfl-1.5 overrides-7.4.0 python-json-logger-2.0.7 pyzmq-24.0.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 tensorboardX-2.6 types-python-dateutil-2.8.19.14 uri-template-1.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill==0.3.6 (from -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 1))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting metaflow==2.7.15 (from -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading metaflow-2.7.15-py2.py3-none-any.whl (863 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.0/864.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray==2.2.0 (from -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3))\n",
            "  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6 (from -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 4))\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (2.31.0)\n",
            "Collecting boto3 (from metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading boto3-1.33.12-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylint (from metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading pylint-3.0.3-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.6/510.6 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (8.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (1.4.0)\n",
            "Collecting virtualenv>=20.0.24 (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3))\n",
            "  Downloading virtualenv-20.25.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (1.59.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (23.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.24->ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (4.1.0)\n",
            "Collecting botocore<1.34.0,>=1.33.12 (from boto3->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading botocore-1.33.12-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.9.0,>=0.8.2 (from boto3->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.2.0->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 3)) (0.13.2)\n",
            "Collecting astroid<=3.1.0-dev0,>=3.0.1 (from pylint->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading astroid-3.0.2-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.2/275.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort!=5.13.0,<6,>=4.2.5 (from pylint->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading isort-5.13.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.8,>=0.6 (from pylint->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting tomlkit>=0.10.1 (from pylint->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2))\n",
            "  Downloading tomlkit-0.12.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from astroid<=3.1.0-dev0,>=3.0.1->pylint->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.12->boto3->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.12->boto3->metaflow==2.7.15->-r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt (line 2)) (1.16.0)\n",
            "Installing collected packages: distlib, virtualenv, tomlkit, numpy, mccabe, jmespath, isort, dill, astroid, pylint, botocore, s3transfer, ray, boto3, metaflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "flax 0.7.5 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "jax 0.4.20 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "jaxlib 0.4.20+cuda11.cudnn86 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astroid-3.0.2 boto3-1.33.12 botocore-1.33.12 dill-0.3.6 distlib-0.3.8 isort-5.13.1 jmespath-1.0.1 mccabe-0.7.0 metaflow-2.7.15 numpy-1.21.6 pylint-3.0.3 ray-2.2.0 s3transfer-0.8.2 tomlkit-0.12.3 virtualenv-20.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/intel/openfl.git\n",
        "!pip install -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt\n",
        "import os\n",
        "os.environ[\"USERNAME\"] = \"colab\"\n",
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmO1l6fj3qLA",
        "outputId": "4f54f3af-9b7f-43c8-83be-29ee4ea2b2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g1uCwXvXM9KVX977KTl_3iIvjINXaY8S\n",
            "To: /content/64x64.rar\n",
            "100% 56.4M/56.4M [00:01<00:00, 42.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown '1g1uCwXvXM9KVX977KTl_3iIvjINXaY8S'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRK5OhRX3xn7"
      },
      "outputs": [],
      "source": [
        "import rarfile\n",
        "\n",
        "rar_path = '/content/64x64.rar'\n",
        "\n",
        "# Giải nén tệp .rar\n",
        "with rarfile.RarFile(rar_path, 'r') as rf:\n",
        "    rf.extractall('/content/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EJj9UeT4Ne5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split, ConcatDataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size_train = 64\n",
        "batch_size_test = 64\n",
        "log_interval = 5\n",
        "seed = 18\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.dataset = ImageFolder(root_dir, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[idx]\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "datasetfull = CustomDataset(root_dir='/content/data/64x64', transform=transform)\n",
        "\n",
        "# Load 50% dataset\n",
        "desired_size = int(0.5 * len(datasetfull))\n",
        "remaining_size = len(datasetfull) - desired_size\n",
        "dataset, _ = random_split(datasetfull, [desired_size, remaining_size], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n",
        "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chia dataset thành 3 subset theo 5 nhãn\n",
        "def split_dataset_by_labels(dataset, labels):\n",
        "    selected_indices = [i for i in range(len(dataset)) if dataset[i][1] == labels]\n",
        "    return torch.utils.data.Subset(dataset, selected_indices)\n",
        "\n",
        "subset_0 = split_dataset_by_labels(dataset, 0)\n",
        "subset_1 = split_dataset_by_labels(dataset, 1)\n",
        "subset_2 = split_dataset_by_labels(dataset, 2)\n",
        "subset_3 = split_dataset_by_labels(dataset, 3)\n",
        "subset_4 = split_dataset_by_labels(dataset, 4)"
      ],
      "metadata": {
        "id": "mLmYbZcnb8Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chia từng subset thành các bộ dữ liệu theo tỷ lệ\n",
        "split_subset_0 = random_split(subset_0, [int(len(subset_0)*0.8), 0, len(subset_0) - int(len(subset_0)*0.8)], generator=torch.Generator().manual_seed(seed))\n",
        "split_subset_1 = random_split(subset_1, [int(len(subset_1)*0.2), len(subset_1) - int(len(subset_1)*0.2), 0], generator=torch.Generator().manual_seed(seed))\n",
        "split_subset_2 = random_split(subset_2, [int(len(subset_2)*0.1), int(len(subset_2)*0.2), len(subset_2) - int(len(subset_2)*0.1) - int(len(subset_2)*0.2)], generator=torch.Generator().manual_seed(seed))\n",
        "split_subset_3 = random_split(subset_3, [0, int(len(subset_3)*0.1), len(subset_3) - int(len(subset_3)*0.1)], generator=torch.Generator().manual_seed(seed))\n",
        "split_subset_4 = random_split(subset_4, [int(len(subset_4)*0.2), int(len(subset_4)*0.5), len(subset_4) - int(len(subset_4)*0.5) - int(len(subset_4)*0.2)], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "#Xây dựng dataset cho các node\n",
        "final_subset_A = ConcatDataset([split_subset_0[0], split_subset_1[0], split_subset_2[0], split_subset_3[0], split_subset_4[0]])\n",
        "final_subset_B = ConcatDataset([split_subset_0[1], split_subset_1[1], split_subset_2[1], split_subset_3[1], split_subset_4[1]])\n",
        "final_subset_C = ConcatDataset([split_subset_0[2], split_subset_1[2], split_subset_2[2], split_subset_3[2], split_subset_4[2]])\n"
      ],
      "metadata": {
        "id": "2jfmZQgDfnL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chia dataset tại các node thành training set và validation set\n",
        "train_sizeA = int(0.7 * len(final_subset_A))\n",
        "val_sizeA = len(final_subset_A) - train_sizeA\n",
        "trainA, valA = torch.utils.data.random_split(final_subset_A, [train_sizeA, val_sizeA], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "train_sizeB = int(0.7 * len(final_subset_B))\n",
        "val_sizeB = len(final_subset_B) - train_sizeB\n",
        "trainB, valB = torch.utils.data.random_split(final_subset_B, [train_sizeB, val_sizeB], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "train_sizeC = int(0.7 * len(final_subset_C))\n",
        "val_sizeC = len(final_subset_C) - train_sizeC\n",
        "trainC, valC = torch.utils.data.random_split(final_subset_C, [train_sizeC, val_sizeC], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "\n",
        "train_loaderA = DataLoader(trainA, batch_size=64, shuffle=True)\n",
        "val_loaderA = DataLoader(valA, batch_size=64, shuffle=False)\n",
        "\n",
        "train_loaderB = DataLoader(trainB, batch_size=64, shuffle=True)\n",
        "val_loaderB = DataLoader(valB, batch_size=64, shuffle=False)\n",
        "\n",
        "train_loaderC = DataLoader(trainC, batch_size=64, shuffle=True)\n",
        "val_loaderC = DataLoader(valC, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "MSuN57XbzjTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idyg_rzH6bDa"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1)\n",
        "        self.pool = nn.MaxPool2d(2, stride=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 59 * 59, 500)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(500, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def inference(network, test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        network = network.to('cuda:0')\n",
        "    network.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total_samples_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "          if torch.cuda.is_available():\n",
        "                inputs = inputs.to('cuda:0')\n",
        "                labels = labels.to('cuda:0')\n",
        "          outputs = network(inputs)\n",
        "          test_loss += criterion(outputs, labels).item()\n",
        "          _, predicted_val = torch.max(outputs.data, 1)\n",
        "          total_samples_val += labels.size(0)\n",
        "          correct += (predicted_val == labels).sum().item()\n",
        "\n",
        "    test_loss /= total_samples_val\n",
        "    accuracy = correct / total_samples_val\n",
        "\n",
        "    print('\\nTest set: loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, total_samples_val, 100. * accuracy))\n",
        "\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate\n",
        "class_names = [\"Adware\", \"Banking Malware\", \"Mobile Riskware\", \"SMS Malware\", \"Benign\"]\n",
        "\n",
        "def evaluate_model(network, test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        network = network.to('cuda:0')\n",
        "    network.eval()\n",
        "\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = inputs.to('cuda:0')\n",
        "                labels = labels.to('cuda:0')\n",
        "\n",
        "            outputs = network(inputs)\n",
        "            _, predicted_val = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_predicted.extend(predicted_val.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    precision = precision_score(all_labels, all_predicted, average='weighted')\n",
        "    recall = recall_score(all_labels, all_predicted, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
        "\n",
        "    print('Precision: {:.4f}'.format(precision))\n",
        "    print('Recall: {:.4f}'.format(recall))\n",
        "    print('F1 Score: {:.4f}'.format(f1))\n",
        "\n",
        "    # Classification report provides precision, recall, and F1-score for each class\n",
        "    print('\\nClassification Report:')\n",
        "    print(classification_report(all_labels, all_predicted))\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predicted)\n",
        "\n",
        "    plt.figure(figsize=(len(class_names), len(class_names)))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TaP8sDs2T-XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Centralized Learning"
      ],
      "metadata": {
        "id": "-nT-GUH6QNXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "modelA = MyModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelA.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model on dataset A\n",
        "num_epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelA.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    modelA.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loaderA:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = modelA(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Training accuracy\n",
        "    train_accuracy = total_correct / total_samples\n",
        "\n",
        "    # Validation loop\n",
        "    modelA.eval()\n",
        "    total_correct_val = 0\n",
        "    total_samples_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loaderA:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = modelA(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted_val = torch.max(outputs.data, 1)\n",
        "            total_samples_val += labels.size(0)\n",
        "            total_correct_val += (predicted_val == labels).sum().item()\n",
        "\n",
        "    # Validation accuracy\n",
        "    val_accuracy = total_correct_val / total_samples_val\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, '\n",
        "          f'Train Accuracy: {train_accuracy * 100:.2f}%, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d26bb2-5cb6-49a5-ee95-de45ae1bcf6a",
        "id": "6hAqJX2CQNX_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 2.5758, Train Accuracy: 43.34%, Val Loss: 3.4170, Val Accuracy: 63.66\n",
            "Epoch [2/5], Loss: 0.9219, Train Accuracy: 64.61%, Val Loss: 0.4777, Val Accuracy: 81.02\n",
            "Epoch [3/5], Loss: 0.5453, Train Accuracy: 81.41%, Val Loss: 0.4354, Val Accuracy: 84.49\n",
            "Epoch [4/5], Loss: 0.2477, Train Accuracy: 88.07%, Val Loss: 0.2686, Val Accuracy: 85.42\n",
            "Epoch [5/5], Loss: 0.5678, Train Accuracy: 91.45%, Val Loss: 0.2509, Val Accuracy: 86.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop on general validation set\n",
        "modelA.eval()\n",
        "total_correct_val = 0\n",
        "total_samples_val = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = modelA(inputs)\n",
        "        val_loss = criterion(outputs, labels)\n",
        "        _, predicted_val = torch.max(outputs.data, 1)\n",
        "        total_samples_val += labels.size(0)\n",
        "        total_correct_val += (predicted_val == labels).sum().item()\n",
        "# Calculate validation accuracy\n",
        "val_accuracy = total_correct_val / total_samples_val\n",
        "print(f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbW58O9H5t4m",
        "outputId": "9f6feacb-9c66-4a36-c6ea-7c27c0928ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 6.2985, Val Accuracy: 54.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "modelB = MyModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelB.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model on dataset B\n",
        "num_epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelB.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    modelB.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loaderB:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = modelB(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Training accuracy\n",
        "    train_accuracy = total_correct / total_samples\n",
        "\n",
        "    # Validation loop\n",
        "    modelB.eval()\n",
        "    total_correct_val = 0\n",
        "    total_samples_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loaderB:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = modelB(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted_val = torch.max(outputs.data, 1)\n",
        "            total_samples_val += labels.size(0)\n",
        "            total_correct_val += (predicted_val == labels).sum().item()\n",
        "\n",
        "    # Validation accuracy\n",
        "    val_accuracy = total_correct_val / total_samples_val\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, '\n",
        "          f'Train Accuracy: {train_accuracy * 100:.2f}%, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUIseEjUGcgB",
        "outputId": "35c62a5d-28ee-4b66-8725-fbea7b10c3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.2758, Train Accuracy: 55.43%, Val Loss: 0.9201, Val Accuracy: 80.10\n",
            "Epoch [2/5], Loss: 0.4111, Train Accuracy: 79.16%, Val Loss: 0.2124, Val Accuracy: 86.43\n",
            "Epoch [3/5], Loss: 0.4494, Train Accuracy: 87.36%, Val Loss: 0.1315, Val Accuracy: 89.28\n",
            "Epoch [4/5], Loss: 0.2176, Train Accuracy: 90.19%, Val Loss: 0.1186, Val Accuracy: 89.41\n",
            "Epoch [5/5], Loss: 0.3518, Train Accuracy: 93.57%, Val Loss: 0.1486, Val Accuracy: 89.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop on general validation set\n",
        "modelB.eval()\n",
        "total_correct_val = 0\n",
        "total_samples_val = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = modelB(inputs)\n",
        "        val_loss = criterion(outputs, labels)\n",
        "        _, predicted_val = torch.max(outputs.data, 1)\n",
        "        total_samples_val += labels.size(0)\n",
        "        total_correct_val += (predicted_val == labels).sum().item()\n",
        "# Calculate validation accuracy\n",
        "val_accuracy = total_correct_val / total_samples_val\n",
        "print(f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I96kMI5KHMet",
        "outputId": "49438810-c21a-44c1-f2a2-7d001fcce4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 2.7423, Val Accuracy: 76.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "modelC = MyModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelC.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model on dataset C\n",
        "num_epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelC.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    modelC.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loaderC:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = modelC(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Training accuracy\n",
        "    train_accuracy = total_correct / total_samples\n",
        "\n",
        "    # Validation loop\n",
        "    modelC.eval()\n",
        "    total_correct_val = 0\n",
        "    total_samples_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loaderC:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = modelC(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted_val = torch.max(outputs.data, 1)\n",
        "            total_samples_val += labels.size(0)\n",
        "            total_correct_val += (predicted_val == labels).sum().item()\n",
        "\n",
        "    # Validation accuracy\n",
        "    val_accuracy = total_correct_val / total_samples_val\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, '\n",
        "          f'Train Accuracy: {train_accuracy * 100:.2f}%, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMAiAiDyHRsv",
        "outputId": "350e0de8-85c9-49d2-8d96-4db89aa72be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3116, Train Accuracy: 75.41%, Val Loss: 0.0430, Val Accuracy: 86.27\n",
            "Epoch [2/5], Loss: 0.1393, Train Accuracy: 91.61%, Val Loss: 0.1126, Val Accuracy: 90.46\n",
            "Epoch [3/5], Loss: 0.0452, Train Accuracy: 94.81%, Val Loss: 0.0933, Val Accuracy: 92.24\n",
            "Epoch [4/5], Loss: 0.1385, Train Accuracy: 96.47%, Val Loss: 0.0094, Val Accuracy: 92.55\n",
            "Epoch [5/5], Loss: 0.0784, Train Accuracy: 97.77%, Val Loss: 0.0051, Val Accuracy: 92.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop on general validation set\n",
        "modelC.eval()\n",
        "total_correct_val = 0\n",
        "total_samples_val = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = modelC(inputs)\n",
        "        val_loss = criterion(outputs, labels)\n",
        "        _, predicted_val = torch.max(outputs.data, 1)\n",
        "        total_samples_val += labels.size(0)\n",
        "        total_correct_val += (predicted_val == labels).sum().item()\n",
        "# Calculate validation accuracy\n",
        "val_accuracy = total_correct_val / total_samples_val\n",
        "print(f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yld7rWHDHbDt",
        "outputId": "efac016f-37ed-4874-d31b-fe7ada4ed075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 3.0159, Val Accuracy: 78.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Federated Learning"
      ],
      "metadata": {
        "id": "V40uBn3oquGv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShvYJAAVz9xg"
      },
      "outputs": [],
      "source": [
        "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
        "from openfl.experimental.runtime import LocalRuntime\n",
        "from openfl.experimental.placement import aggregator, collaborator\n",
        "\n",
        "# Aggregation Function\n",
        "def FedAvg(models, weights=None):\n",
        "    models = [model.to('cpu') for model in models]\n",
        "    new_model = models[0]\n",
        "    state_dicts = [model.state_dict() for model in models]\n",
        "    state_dict = new_model.state_dict()\n",
        "    for key in models[1].state_dict():\n",
        "        state_dict[key] = torch.from_numpy(np.average([state[key].numpy() for state in state_dicts],\n",
        "                                                      axis=0,\n",
        "                                                      weights=weights))\n",
        "    new_model.load_state_dict(state_dict)\n",
        "    return new_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fROWYmrJ4g7a",
        "outputId": "ad21c5b2-014c-40f3-f6e8-2af15baf738f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregator step \"start\" registered\n",
            "Collaborator step \"aggregated_model_validation\" registered\n",
            "Collaborator step \"train\" registered\n",
            "Collaborator step \"local_model_validation\" registered\n",
            "Aggregator step \"join\" registered\n",
            "Aggregator step \"end\" registered\n"
          ]
        }
      ],
      "source": [
        "# Design Workflow\n",
        "class FederatedFlow(FLSpec):\n",
        "\n",
        "    def __init__(self, model = None, optimizer = None, criterion = None, rounds=5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        if model is not None:\n",
        "            self.model = model\n",
        "            self.optimizer = optimizer\n",
        "            self.criterion = criterion\n",
        "        else:\n",
        "            self.model = MyModel()\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "        self.rounds = rounds\n",
        "\n",
        "    @aggregator\n",
        "    def start(self):\n",
        "        print(f'Performing initialization for model')\n",
        "        self.collaborators = self.runtime.collaborators\n",
        "        self.private = 10\n",
        "        self.current_round = 0\n",
        "        self.next(self.aggregated_model_validation,foreach='collaborators',exclude=['private'])\n",
        "\n",
        "    @collaborator\n",
        "    def aggregated_model_validation(self):\n",
        "        print(f'Round: {self.current_round}')\n",
        "        print(f'Performing aggregated model validation for collaborator {self.input}')\n",
        "        self.agg_validation_score = inference(self.model,self.test_loader)\n",
        "        print(f'{self.input} value of {self.agg_validation_score}')\n",
        "        self.next(self.train)\n",
        "\n",
        "    @collaborator\n",
        "    def train(self):\n",
        "      if torch.cuda.is_available():\n",
        "        self.model = self.model.to('cuda:0')\n",
        "      self.model.train()\n",
        "      self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "      self.criterion = nn.CrossEntropyLoss()\n",
        "      total_correct = 0\n",
        "      total_samples = 0\n",
        "\n",
        "      for batch_idx, (inputs, labels) in enumerate(self.train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "          inputs = inputs.to(\"cuda:0\")\n",
        "          labels = labels.to(\"cuda:0\")\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "             batch_idx * len(inputs), len(self.train_loader.dataset),\n",
        "            100. * batch_idx / len(self.train_loader), loss.item()))\n",
        "          self.loss = loss.item()\n",
        "          torch.save(self.model.state_dict(), 'model.pth')\n",
        "          torch.save(self.optimizer.state_dict(), 'optimizer.pth')\n",
        "\n",
        "      self.training_completed = True\n",
        "      self.next(self.local_model_validation)\n",
        "\n",
        "    @collaborator\n",
        "    def local_model_validation(self):\n",
        "        self.local_validation_score = inference(self.model,self.test_loader)\n",
        "        print(f'Doing local model validation for collaborator {self.input}: {self.local_validation_score}')\n",
        "        self.next(self.join, exclude=['training_completed'])\n",
        "\n",
        "    @aggregator\n",
        "    def join(self,inputs):\n",
        "        self.average_loss = sum(input.loss for input in inputs)/len(inputs)\n",
        "        self.aggregated_model_accuracy = sum(input.agg_validation_score for input in inputs)/len(inputs)\n",
        "        self.local_model_accuracy = sum(input.local_validation_score for input in inputs)/len(inputs)\n",
        "        print(f'Average aggregated model validation values = {self.aggregated_model_accuracy}')\n",
        "        print(f'Average training loss = {self.average_loss}')\n",
        "        print(f'Average local model validation values = {self.local_model_accuracy}')\n",
        "        self.model = FedAvg([input.model for input in inputs])\n",
        "        self.optimizer = [input.optimizer for input in inputs][0]\n",
        "        self.current_round += 1\n",
        "        if self.current_round < self.rounds:\n",
        "            self.next(self.aggregated_model_validation, foreach='collaborators', exclude=['private'])\n",
        "        else:\n",
        "            self.global_validation_score = inference(self.model, testloader)\n",
        "            print (f'Global score: {self.global_validation_score}')\n",
        "            torch.save(self.model.state_dict(), 'final_model.pth')\n",
        "            self.next(self.end)\n",
        "\n",
        "    @aggregator\n",
        "    def end(self):\n",
        "        print(f'This is the end of the flow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmohxazF4keT",
        "outputId": "d484ebd8-a025-48dc-ab7b-81e68a94df5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local runtime collaborators = ['A', 'B', 'C']\n"
          ]
        }
      ],
      "source": [
        "# Setup participants\n",
        "aggregator = Aggregator()\n",
        "aggregator.private_attributes = {}\n",
        "\n",
        "# Setup collaborators with private attributes\n",
        "collaborator_names = ['A', 'B', 'C']\n",
        "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
        "for idx, collaborator in enumerate(collaborators):\n",
        "    if idx == 0:\n",
        "      collaborator.private_attributes = {\n",
        "            'train_loader': torch.utils.data.DataLoader(trainA,batch_size=batch_size_train, shuffle=True),\n",
        "            'test_loader': torch.utils.data.DataLoader(valA,batch_size=batch_size_train, shuffle=True)\n",
        "      }\n",
        "    elif idx == 1:\n",
        "      collaborator.private_attributes = {\n",
        "            'train_loader': torch.utils.data.DataLoader(trainB,batch_size=batch_size_train, shuffle=True),\n",
        "            'test_loader': torch.utils.data.DataLoader(valB,batch_size=batch_size_train, shuffle=True)\n",
        "      }\n",
        "    else:\n",
        "      collaborator.private_attributes = {\n",
        "            'train_loader': torch.utils.data.DataLoader(trainC,batch_size=batch_size_train, shuffle=True),\n",
        "            'test_loader': torch.utils.data.DataLoader(valC,batch_size=batch_size_test, shuffle=True)\n",
        "      }\n",
        "\n",
        "local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators, backend='single_process')\n",
        "print(f'Local runtime collaborators = {local_runtime.collaborators}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIpsvZUN4w3Q",
        "outputId": "f3f83767-179a-4b6f-ac62-048485b167ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating local datastore in current directory (/content/.metaflow)\n",
            "\n",
            "Calling start\n",
            "Performing initialization for model\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 0\n",
            "Performing aggregated model validation for collaborator A\n",
            "\n",
            "Test set: loss: 0.0262, Accuracy: 83/432 (19.21%)\n",
            "\n",
            "A value of 0.19212962962962962\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1006 (0%)]\tLoss: 1.614855\n",
            "Train Epoch: 1 [320/1006 (31%)]\tLoss: 16.642025\n",
            "Train Epoch: 1 [640/1006 (62%)]\tLoss: 4.624014\n",
            "Train Epoch: 1 [690/1006 (94%)]\tLoss: 4.053060\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0453, Accuracy: 284/432 (65.74%)\n",
            "\n",
            "Doing local model validation for collaborator A: 0.6574074074074074\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 0\n",
            "Performing aggregated model validation for collaborator B\n",
            "\n",
            "Test set: loss: 0.0267, Accuracy: 278/774 (35.92%)\n",
            "\n",
            "B value of 0.35917312661498707\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1804 (0%)]\tLoss: 1.598459\n",
            "Train Epoch: 1 [320/1804 (17%)]\tLoss: 14.250973\n",
            "Train Epoch: 1 [640/1804 (34%)]\tLoss: 6.502986\n",
            "Train Epoch: 1 [960/1804 (52%)]\tLoss: 2.394323\n",
            "Train Epoch: 1 [1280/1804 (69%)]\tLoss: 1.543549\n",
            "Train Epoch: 1 [1600/1804 (86%)]\tLoss: 1.989673\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0161, Accuracy: 612/774 (79.07%)\n",
            "\n",
            "Doing local model validation for collaborator B: 0.7906976744186046\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 0\n",
            "Performing aggregated model validation for collaborator C\n",
            "\n",
            "Test set: loss: 0.0267, Accuracy: 38/1289 (2.95%)\n",
            "\n",
            "C value of 0.02948021722265322\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/3005 (0%)]\tLoss: 1.636967\n",
            "Train Epoch: 1 [320/3005 (11%)]\tLoss: 10.541517\n",
            "Train Epoch: 1 [640/3005 (21%)]\tLoss: 7.970286\n",
            "Train Epoch: 1 [960/3005 (32%)]\tLoss: 2.614876\n",
            "Train Epoch: 1 [1280/3005 (43%)]\tLoss: 1.423240\n",
            "Train Epoch: 1 [1600/3005 (53%)]\tLoss: 2.757693\n",
            "Train Epoch: 1 [1920/3005 (64%)]\tLoss: 1.061021\n",
            "Train Epoch: 1 [2240/3005 (74%)]\tLoss: 0.885848\n",
            "Train Epoch: 1 [2560/3005 (85%)]\tLoss: 0.335332\n",
            "Train Epoch: 1 [2880/3005 (96%)]\tLoss: 0.517550\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0079, Accuracy: 1087/1289 (84.33%)\n",
            "\n",
            "Doing local model validation for collaborator C: 0.843289371605896\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.19359432448908998\n",
            "Average training loss = 2.1867608626683555\n",
            "Average local model validation values = 0.7637981511439694\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 1\n",
            "Performing aggregated model validation for collaborator A\n",
            "\n",
            "Test set: loss: 0.0256, Accuracy: 132/432 (30.56%)\n",
            "\n",
            "A value of 0.3055555555555556\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1006 (0%)]\tLoss: 1.591943\n",
            "Train Epoch: 1 [320/1006 (31%)]\tLoss: 0.807941\n",
            "Train Epoch: 1 [640/1006 (62%)]\tLoss: 0.965355\n",
            "Train Epoch: 1 [690/1006 (94%)]\tLoss: 0.950534\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0102, Accuracy: 341/432 (78.94%)\n",
            "\n",
            "Doing local model validation for collaborator A: 0.7893518518518519\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 1\n",
            "Performing aggregated model validation for collaborator B\n",
            "\n",
            "Test set: loss: 0.0226, Accuracy: 389/774 (50.26%)\n",
            "\n",
            "B value of 0.5025839793281653\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1804 (0%)]\tLoss: 1.502082\n",
            "Train Epoch: 1 [320/1804 (17%)]\tLoss: 0.810527\n",
            "Train Epoch: 1 [640/1804 (34%)]\tLoss: 0.847917\n",
            "Train Epoch: 1 [960/1804 (52%)]\tLoss: 0.570985\n",
            "Train Epoch: 1 [1280/1804 (69%)]\tLoss: 0.609706\n",
            "Train Epoch: 1 [1600/1804 (86%)]\tLoss: 0.483609\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0071, Accuracy: 650/774 (83.98%)\n",
            "\n",
            "Doing local model validation for collaborator B: 0.8397932816537468\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 1\n",
            "Performing aggregated model validation for collaborator C\n",
            "\n",
            "Test set: loss: 0.0204, Accuracy: 648/1289 (50.27%)\n",
            "\n",
            "C value of 0.5027152831652444\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/3005 (0%)]\tLoss: 1.219678\n",
            "Train Epoch: 1 [320/3005 (11%)]\tLoss: 0.533964\n",
            "Train Epoch: 1 [640/3005 (21%)]\tLoss: 0.587345\n",
            "Train Epoch: 1 [960/3005 (32%)]\tLoss: 0.437441\n",
            "Train Epoch: 1 [1280/3005 (43%)]\tLoss: 0.490508\n",
            "Train Epoch: 1 [1600/3005 (53%)]\tLoss: 0.187944\n",
            "Train Epoch: 1 [1920/3005 (64%)]\tLoss: 0.230273\n",
            "Train Epoch: 1 [2240/3005 (74%)]\tLoss: 0.277060\n",
            "Train Epoch: 1 [2560/3005 (85%)]\tLoss: 0.491278\n",
            "Train Epoch: 1 [2880/3005 (96%)]\tLoss: 0.437043\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0047, Accuracy: 1154/1289 (89.53%)\n",
            "\n",
            "Doing local model validation for collaborator C: 0.8952676493405741\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.4369516060163218\n",
            "Average training loss = 0.6237285931905111\n",
            "Average local model validation values = 0.8414709276153909\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 2\n",
            "Performing aggregated model validation for collaborator A\n",
            "\n",
            "Test set: loss: 0.0185, Accuracy: 209/432 (48.38%)\n",
            "\n",
            "A value of 0.4837962962962963\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1006 (0%)]\tLoss: 1.032274\n",
            "Train Epoch: 1 [320/1006 (31%)]\tLoss: 0.514463\n",
            "Train Epoch: 1 [640/1006 (62%)]\tLoss: 0.638158\n",
            "Train Epoch: 1 [690/1006 (94%)]\tLoss: 0.861412\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0071, Accuracy: 368/432 (85.19%)\n",
            "\n",
            "Doing local model validation for collaborator A: 0.8518518518518519\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 2\n",
            "Performing aggregated model validation for collaborator B\n",
            "\n",
            "Test set: loss: 0.0126, Accuracy: 520/774 (67.18%)\n",
            "\n",
            "B value of 0.6718346253229974\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1804 (0%)]\tLoss: 1.032639\n",
            "Train Epoch: 1 [320/1804 (17%)]\tLoss: 0.545784\n",
            "Train Epoch: 1 [640/1804 (34%)]\tLoss: 0.640470\n",
            "Train Epoch: 1 [960/1804 (52%)]\tLoss: 0.395897\n",
            "Train Epoch: 1 [1280/1804 (69%)]\tLoss: 0.706523\n",
            "Train Epoch: 1 [1600/1804 (86%)]\tLoss: 0.793583\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0059, Accuracy: 678/774 (87.60%)\n",
            "\n",
            "Doing local model validation for collaborator B: 0.875968992248062\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 2\n",
            "Performing aggregated model validation for collaborator C\n",
            "\n",
            "Test set: loss: 0.0089, Accuracy: 1042/1289 (80.84%)\n",
            "\n",
            "C value of 0.8083785880527541\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/3005 (0%)]\tLoss: 0.624213\n",
            "Train Epoch: 1 [320/3005 (11%)]\tLoss: 0.347457\n",
            "Train Epoch: 1 [640/3005 (21%)]\tLoss: 0.412932\n",
            "Train Epoch: 1 [960/3005 (32%)]\tLoss: 0.222634\n",
            "Train Epoch: 1 [1280/3005 (43%)]\tLoss: 0.197324\n",
            "Train Epoch: 1 [1600/3005 (53%)]\tLoss: 0.126804\n",
            "Train Epoch: 1 [1920/3005 (64%)]\tLoss: 0.448238\n",
            "Train Epoch: 1 [2240/3005 (74%)]\tLoss: 0.137440\n",
            "Train Epoch: 1 [2560/3005 (85%)]\tLoss: 0.290022\n",
            "Train Epoch: 1 [2880/3005 (96%)]\tLoss: 0.154864\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0033, Accuracy: 1192/1289 (92.47%)\n",
            "\n",
            "Doing local model validation for collaborator C: 0.9247478665632273\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.6546698365573492\n",
            "Average training loss = 0.6032860974470774\n",
            "Average local model validation values = 0.884189570221047\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 3\n",
            "Performing aggregated model validation for collaborator A\n",
            "\n",
            "Test set: loss: 0.0145, Accuracy: 275/432 (63.66%)\n",
            "\n",
            "A value of 0.6365740740740741\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1006 (0%)]\tLoss: 0.786696\n",
            "Train Epoch: 1 [320/1006 (31%)]\tLoss: 0.508838\n",
            "Train Epoch: 1 [640/1006 (62%)]\tLoss: 0.471594\n",
            "Train Epoch: 1 [690/1006 (94%)]\tLoss: 0.746777\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0066, Accuracy: 376/432 (87.04%)\n",
            "\n",
            "Doing local model validation for collaborator A: 0.8703703703703703\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 3\n",
            "Performing aggregated model validation for collaborator B\n",
            "\n",
            "Test set: loss: 0.0099, Accuracy: 642/774 (82.95%)\n",
            "\n",
            "B value of 0.8294573643410853\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1804 (0%)]\tLoss: 0.779305\n",
            "Train Epoch: 1 [320/1804 (17%)]\tLoss: 0.457099\n",
            "Train Epoch: 1 [640/1804 (34%)]\tLoss: 0.266325\n",
            "Train Epoch: 1 [960/1804 (52%)]\tLoss: 0.403895\n",
            "Train Epoch: 1 [1280/1804 (69%)]\tLoss: 0.321633\n",
            "Train Epoch: 1 [1600/1804 (86%)]\tLoss: 0.402074\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0049, Accuracy: 699/774 (90.31%)\n",
            "\n",
            "Doing local model validation for collaborator B: 0.9031007751937985\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 3\n",
            "Performing aggregated model validation for collaborator C\n",
            "\n",
            "Test set: loss: 0.0061, Accuracy: 1127/1289 (87.43%)\n",
            "\n",
            "C value of 0.8743211792086889\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/3005 (0%)]\tLoss: 0.385257\n",
            "Train Epoch: 1 [320/3005 (11%)]\tLoss: 0.314744\n",
            "Train Epoch: 1 [640/3005 (21%)]\tLoss: 0.316090\n",
            "Train Epoch: 1 [960/3005 (32%)]\tLoss: 0.239108\n",
            "Train Epoch: 1 [1280/3005 (43%)]\tLoss: 0.124802\n",
            "Train Epoch: 1 [1600/3005 (53%)]\tLoss: 0.285322\n",
            "Train Epoch: 1 [1920/3005 (64%)]\tLoss: 0.256013\n",
            "Train Epoch: 1 [2240/3005 (74%)]\tLoss: 0.141700\n",
            "Train Epoch: 1 [2560/3005 (85%)]\tLoss: 0.204699\n",
            "Train Epoch: 1 [2880/3005 (96%)]\tLoss: 0.262224\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0040, Accuracy: 1180/1289 (91.54%)\n",
            "\n",
            "Doing local model validation for collaborator C: 0.9154383242823895\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.7801175392079495\n",
            "Average training loss = 0.47035815318425495\n",
            "Average local model validation values = 0.8963031566155194\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 4\n",
            "Performing aggregated model validation for collaborator A\n",
            "\n",
            "Test set: loss: 0.0136, Accuracy: 274/432 (63.43%)\n",
            "\n",
            "A value of 0.6342592592592593\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1006 (0%)]\tLoss: 0.886383\n",
            "Train Epoch: 1 [320/1006 (31%)]\tLoss: 0.510772\n",
            "Train Epoch: 1 [640/1006 (62%)]\tLoss: 0.393492\n",
            "Train Epoch: 1 [690/1006 (94%)]\tLoss: 0.312449\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0069, Accuracy: 374/432 (86.57%)\n",
            "\n",
            "Doing local model validation for collaborator A: 0.8657407407407407\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 4\n",
            "Performing aggregated model validation for collaborator B\n",
            "\n",
            "Test set: loss: 0.0096, Accuracy: 627/774 (81.01%)\n",
            "\n",
            "B value of 0.810077519379845\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1804 (0%)]\tLoss: 0.666783\n",
            "Train Epoch: 1 [320/1804 (17%)]\tLoss: 0.383028\n",
            "Train Epoch: 1 [640/1804 (34%)]\tLoss: 0.241430\n",
            "Train Epoch: 1 [960/1804 (52%)]\tLoss: 0.540906\n",
            "Train Epoch: 1 [1280/1804 (69%)]\tLoss: 0.259765\n",
            "Train Epoch: 1 [1600/1804 (86%)]\tLoss: 0.216771\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0068, Accuracy: 689/774 (89.02%)\n",
            "\n",
            "Doing local model validation for collaborator B: 0.8901808785529716\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Round: 4\n",
            "Performing aggregated model validation for collaborator C\n",
            "\n",
            "Test set: loss: 0.0043, Accuracy: 1182/1289 (91.70%)\n",
            "\n",
            "C value of 0.9169899146625291\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/3005 (0%)]\tLoss: 0.170463\n",
            "Train Epoch: 1 [320/3005 (11%)]\tLoss: 0.181352\n",
            "Train Epoch: 1 [640/3005 (21%)]\tLoss: 0.293457\n",
            "Train Epoch: 1 [960/3005 (32%)]\tLoss: 0.179856\n",
            "Train Epoch: 1 [1280/3005 (43%)]\tLoss: 0.131944\n",
            "Train Epoch: 1 [1600/3005 (53%)]\tLoss: 0.196045\n",
            "Train Epoch: 1 [1920/3005 (64%)]\tLoss: 0.101027\n",
            "Train Epoch: 1 [2240/3005 (74%)]\tLoss: 0.162251\n",
            "Train Epoch: 1 [2560/3005 (85%)]\tLoss: 0.113415\n",
            "Train Epoch: 1 [2880/3005 (96%)]\tLoss: 0.131924\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: loss: 0.0033, Accuracy: 1194/1289 (92.63%)\n",
            "\n",
            "Doing local model validation for collaborator C: 0.9262994569433669\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.787108897767211\n",
            "Average training loss = 0.22038152317206064\n",
            "Average local model validation values = 0.8940736920790263\n",
            "\n",
            "Test set: loss: 0.0066, Accuracy: 2127/2493 (85.32%)\n",
            "\n",
            "Global score: 0.8531889290012034\n",
            "\n",
            "Calling end\n",
            "This is the end of the flow\n"
          ]
        }
      ],
      "source": [
        "model = None\n",
        "best_model = None\n",
        "optimizer = None\n",
        "criterion = None\n",
        "flflow = FederatedFlow(model,optimizer, criterion)\n",
        "flflow.runtime = local_runtime\n",
        "flflow.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelG = MyModel()\n",
        "modelG.load_state_dict(torch.load('final_model.pth'))\n",
        "eval = evaluate_model(modelG, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "ugWKTtLHUXQD",
        "outputId": "7f9138c5-0554-4140-e60d-342cfa3e60a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8711\n",
            "Recall: 0.8532\n",
            "F1 Score: 0.8419\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.32      0.48       238\n",
            "           1       0.90      0.74      0.81       362\n",
            "           2       0.77      0.89      0.82       572\n",
            "           3       0.99      0.95      0.97       740\n",
            "           4       0.77      0.98      0.86       581\n",
            "\n",
            "    accuracy                           0.85      2493\n",
            "   macro avg       0.88      0.78      0.79      2493\n",
            "weighted avg       0.87      0.85      0.84      2493\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}